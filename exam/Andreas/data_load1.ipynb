{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhvLML4T15tV"
      },
      "source": [
        "#### Loading and preparing the PCam data for training shallow learning models using tensorflow dataset (tfds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 26246,
          "status": "ok",
          "timestamp": 1674154311420,
          "user": {
            "displayName": "Christian MÃ¸ller Dahl",
            "userId": "12856710001555285310"
          },
          "user_tz": -60
        },
        "id": "XaB64nl72Cij",
        "outputId": "4b6e5648-748c-4364-881c-476d8c206d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sklearn) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.8.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.21.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.28.2)\n",
            "Requirement already satisfied: setuptools-scm>=4 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (6.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.21.4)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from setuptools-scm>=4->matplotlib) (60.9.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
            "Requirement already satisfied: tensorflow in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (60.9.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.21.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: tensorflow_datasets in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.8.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (2.26.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (1.14.1)\n",
            "Requirement already satisfied: promise in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: psutil in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (5.9.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (1.21.4)\n",
            "Requirement already satisfied: tensorflow-metadata in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (1.12.0)\n",
            "Requirement already satisfied: dm-tree in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (0.1.8)\n",
            "Requirement already satisfied: click in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (8.1.3)\n",
            "Requirement already satisfied: termcolor in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: absl-py in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: dill in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (0.3.6)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (3.19.6)\n",
            "Requirement already satisfied: toml in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_datasets) (4.64.1)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.2.0)\n",
            "Requirement already satisfied: zipp in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.10.0)\n",
            "Requirement already satisfied: importlib_resources in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (5.10.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.9)\n",
            "Requirement already satisfied: colorama in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->tensorflow_datasets) (0.4.5)\n",
            "Requirement already satisfied: six in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\andly\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.58.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn\n",
        "!pip install matplotlib\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZlr-oNp15tZ"
      },
      "source": [
        "Loading the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-24T13:39:41.211Z",
          "iopub.status.busy": "2023-01-24T13:39:41.187Z",
          "iopub.status.idle": "2023-01-24T13:39:52.390Z",
          "shell.execute_reply": "2023-01-24T13:39:52.480Z"
        },
        "executionInfo": {
          "elapsed": 10562,
          "status": "ok",
          "timestamp": 1674154321980,
          "user": {
            "displayName": "Christian MÃ¸ller Dahl",
            "userId": "12856710001555285310"
          },
          "user_tz": -60
        },
        "id": "JwxQHGy_15tb"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOKqkr5U15tg"
      },
      "source": [
        "Defining a function that grayscale, resize and flattens the image. This function might also become handy (for deep learning) if the original images are too large for your hardware configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 14,
          "status": "ok",
          "timestamp": 1674154321980,
          "user": {
            "displayName": "Christian MÃ¸ller Dahl",
            "userId": "12856710001555285310"
          },
          "user_tz": -60
        },
        "id": "u2HYPeO615th"
      },
      "outputs": [],
      "source": [
        "def convert_sample(image):\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.image.resize(image,[32,32]).numpy()\n",
        "    image = image.reshape(1,-1)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwyhfJn5-YX5"
      },
      "source": [
        "You can use your google drive to store the data by \"mounting\" it as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4255,
          "status": "ok",
          "timestamp": 1674154326222,
          "user": {
            "displayName": "Christian MÃ¸ller Dahl",
            "userId": "12856710001555285310"
          },
          "user_tz": -60
        },
        "id": "o0PVqLrM7uDA",
        "outputId": "bc6b3537-d505-4994-9dd5-ad8bee23db3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBn2P6Yo15tj"
      },
      "source": [
        "Next we use the tensorflow dataset API - tfds - to load data from your mounted google drive. Note this API requite that you should have copied the entire **patch_camelyon** folder from https://syddanskuni-my.sharepoint.com/:f:/g/personal/cmd_sam_sdu_dk/EiWD2LmuxCJBp-_tfGK7aL8Bair7l5z8FU5sp5pLjlhKwg?e=FLzWno to the /content/drive/MyDrive folder on your google drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-24T13:40:25.023Z",
          "iopub.status.busy": "2023-01-24T13:40:25.010Z"
        },
        "executionInfo": {
          "elapsed": 15035,
          "status": "ok",
          "timestamp": 1674154341255,
          "user": {
            "displayName": "Christian MÃ¸ller Dahl",
            "userId": "12856710001555285310"
          },
          "user_tz": -60
        },
        "id": "ajHSLb1e15tl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:/Users/andly/Desktop/DATA SCIENCE NOTER/AML/exam/patch_camelyon/\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Dataset patch_camelyon: could not find data in C:/Users/andly/Desktop/DATA SCIENCE NOTER/AML/exam/patch_camelyon/. Please make sure to call dataset_builder.download_and_prepare(), or pass download=True to tfds.load() before trying to access the tf.data.Dataset object.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\andly\\Desktop\\DATA SCIENCE NOTER\\AML\\exam\\applied_ML_faelles\\exam\\Andreas\\data_load1.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andly/Desktop/DATA%20SCIENCE%20NOTER/AML/exam/applied_ML_faelles/exam/Andreas/data_load1.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mC:/Users/andly/Desktop/DATA SCIENCE NOTER/AML/exam/patch_camelyon/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andly/Desktop/DATA%20SCIENCE%20NOTER/AML/exam/applied_ML_faelles/exam/Andreas/data_load1.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(data_path)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/andly/Desktop/DATA%20SCIENCE%20NOTER/AML/exam/applied_ML_faelles/exam/Andreas/data_load1.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ds1,ds2,ds3 \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mpatch_camelyon\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andly/Desktop/DATA%20SCIENCE%20NOTER/AML/exam/applied_ML_faelles/exam/Andreas/data_load1.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                         split\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain[:5\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mtest[:2\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mvalidation[:2\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andly/Desktop/DATA%20SCIENCE%20NOTER/AML/exam/applied_ML_faelles/exam/Andreas/data_load1.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                         data_dir \u001b[39m=\u001b[39;49m data_path,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andly/Desktop/DATA%20SCIENCE%20NOTER/AML/exam/applied_ML_faelles/exam/Andreas/data_load1.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                         download\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andly/Desktop/DATA%20SCIENCE%20NOTER/AML/exam/applied_ML_faelles/exam/Andreas/data_load1.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                         batch_size\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m# All data...no batches needed \u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andly/Desktop/DATA%20SCIENCE%20NOTER/AML/exam/applied_ML_faelles/exam/Andreas/data_load1.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                         as_supervised\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m# So that we easily can transform data to numpy format\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/andly/Desktop/DATA%20SCIENCE%20NOTER/AML/exam/applied_ML_faelles/exam/Andreas/data_load1.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                         shuffle_files\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[1;32mc:\\Users\\andly\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[0;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
            "File \u001b[1;32mc:\\Users\\andly\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:629\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    626\u001b[0m as_dataset_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mshuffle_files\u001b[39m\u001b[39m'\u001b[39m, shuffle_files)\n\u001b[0;32m    627\u001b[0m as_dataset_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mread_config\u001b[39m\u001b[39m'\u001b[39m, read_config)\n\u001b[1;32m--> 629\u001b[0m ds \u001b[39m=\u001b[39m dbuilder\u001b[39m.\u001b[39mas_dataset(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mas_dataset_kwargs)\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m with_info:\n\u001b[0;32m    631\u001b[0m   \u001b[39mreturn\u001b[39;00m ds, dbuilder\u001b[39m.\u001b[39minfo\n",
            "File \u001b[1;32mc:\\Users\\andly\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[0;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
            "File \u001b[1;32mc:\\Users\\andly\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:747\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[1;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[39m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir):\n\u001b[1;32m--> 747\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    748\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: could not find data in \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Please make sure to call \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    749\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mdataset_builder.download_and_prepare(), or pass download=True to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    750\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mtfds.load() before trying to access the tf.data.Dataset object.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    751\u001b[0m       \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir_root)\n\u001b[0;32m    752\u001b[0m   )\n\u001b[0;32m    754\u001b[0m \u001b[39m# By default, return all splits\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[39mif\u001b[39;00m split \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mAssertionError\u001b[0m: Dataset patch_camelyon: could not find data in C:/Users/andly/Desktop/DATA SCIENCE NOTER/AML/exam/patch_camelyon/. Please make sure to call dataset_builder.download_and_prepare(), or pass download=True to tfds.load() before trying to access the tf.data.Dataset object."
          ]
        }
      ],
      "source": [
        "data_path = 'C:/Users/andly/Desktop/DATA SCIENCE NOTER/AML/exam/patch_camelyon/'\n",
        "print(data_path)\n",
        "ds1,ds2,ds3 = tfds.load('patch_camelyon',\n",
        "                        split=['train[:5%]','test[:2%]','validation[:2%]'],\n",
        "                        data_dir = data_path,\n",
        "                        download=False,\n",
        "                        batch_size=-1, # All data...no batches needed \n",
        "                        as_supervised=True, # So that we easily can transform data to numpy format\n",
        "                        shuffle_files=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kuVMFWJ15tn"
      },
      "source": [
        "Next we can easily convert both the images and the labels to numpy format "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 30947,
          "status": "ok",
          "timestamp": 1674154372190,
          "user": {
            "displayName": "Christian MÃ¸ller Dahl",
            "userId": "12856710001555285310"
          },
          "user_tz": -60
        },
        "id": "ROyKRTvB15to",
        "outputId": "da37ff05-fc86-475a-f3d4-626445e7b0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training data features (observations,features): (13107, 1024)\n",
            "Shape of training data labels (observations,): (13107,)\n"
          ]
        }
      ],
      "source": [
        "train_dataset       = tfds.as_numpy(ds1)\n",
        "train_dataset_image = np.vstack(list(map(convert_sample,train_dataset[0])))\n",
        "train_dataset_image_Scaled = StandardScaler(with_mean=0, with_std=1).fit_transform(train_dataset_image)\n",
        "train_dataset_label = train_dataset[1].reshape(-1,)    \n",
        "print(f'Shape of training data features (observations,features): {train_dataset_image_Scaled.shape}')\n",
        "print(f'Shape of training data labels (observations,): {train_dataset_label.shape}')\n",
        "\n",
        "validation_dataset  = tfds.as_numpy(ds3)\n",
        "validation_dataset_image = np.vstack(list(map(convert_sample,validation_dataset[0])))\n",
        "validation_dataset_image_Scaled = StandardScaler(with_mean=0, with_std=1).fit_transform(validation_dataset_image)\n",
        "validation_dataset_label = validation_dataset[1].reshape(-1,) \n",
        "   \n",
        "test_dataset        = tfds.as_numpy(ds2)\n",
        "test_dataset_image = np.vstack(list(map(convert_sample,test_dataset[0])))\n",
        "test_dataset_image_Scaled = StandardScaler(with_mean=0, with_std=1).fit_transform(test_dataset_image)\n",
        "test_dataset_label = test_dataset[1].reshape(-1,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ4KbAKP15tr"
      },
      "source": [
        "The data is then ready to be applied for training, validation, testing in a shallow learning model such as the SVM classifier...below just a very very simple illustration on how to construct and train a support vector machine based on the data we have prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 130498,
          "status": "ok",
          "timestamp": 1674154502677,
          "user": {
            "displayName": "Christian MÃ¸ller Dahl",
            "userId": "12856710001555285310"
          },
          "user_tz": -60
        },
        "id": "iw5goz8g15tt",
        "outputId": "059566ce-5769-429d-f6ce-67c36d3b9c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM achieved 51.9% accuracy.\n"
          ]
        }
      ],
      "source": [
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(train_dataset_image_Scaled, train_dataset_label)\n",
        "y_test_hat = clf.predict(test_dataset_image)\n",
        "\n",
        "# Obtain accuracy by using the `accuracy_score` function\n",
        "accuracy_linear = accuracy_score(y_test_hat, test_dataset_label )\n",
        "# Print results\n",
        "print(f'SVM achieved {round(accuracy_linear * 100, 1)}% accuracy.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e008f49cf07b1b250fc62b761173fdb635eda2b6423a39aacdc9e46c6a4e9457"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
